# 시스템 아키텍처

![SKN_3차_ZIPFIT - 시스템 아키텍쳐](https://github.com/user-attachments/assets/91d8e81f-7320-4d7e-87f7-4fd3dcfe049a)

## 1. 전체 아키텍처 개요

### 1.1. 시스템 개요

ZIPFIT은 LLM과 RAG(Retrieval-Augmented Generation) 기술을 활용한 공공주택 공고 기반 맞춤형 정보 제공 AI 에이전트 서비스입니다. 사용자의 자연어 질문을 이해하고, 관련 공고 문서를 검색하여 정확하고 맥락 있는 답변을 생성합니다.

### 1.2. 아키텍처 패턴

본 시스템은 **3-Tier Architecture**와 **Microservices Pattern**을 결합한 하이브리드 아키텍처를 채택했습니다:

- **Presentation Layer**: Vue 3 기반 프론트엔드 애플리케이션
- **Application Layer**: FastAPI 기반 RESTful API 서버
- **Data Layer**: PostgreSQL + pgvector 하이브리드 데이터베이스

### 1.3. 핵심 기술 스택

| 계층 | 기술 스택 | 용도 |
|------|----------|------|
| **Frontend** | Vue 3, TypeScript, Vite | 사용자 인터페이스 및 상호작용 |
| **Backend** | FastAPI, Python 3.12, asyncio | 비동기 API 서버 및 비즈니스 로직 |
| **Database** | PostgreSQL, pgvector | 관계형 데이터 및 벡터 데이터 저장 |
| **AI/ML** | BAAI/bge-m3, Dongjin-kr/ko-reranker, GPT-4o-mini | 임베딩, 재순위화, 답변 생성 |

---

## 2. 시스템 구성 요소

### 2.1. Frontend Layer

#### 2.1.1. 기술 스택
- **프레임워크**: Vue 3 (Composition API)
- **언어**: TypeScript
- **빌드 도구**: Vite 7.1.11
- **상태 관리**: Pinia 3.0.3
- **라우팅**: Vue Router 4.6.3

#### 2.1.2. 주요 컴포넌트

**페이지 컴포넌트**:
- `AiView.vue`: AI 채팅 인터페이스
  - 실시간 메시지 송수신
  - 대화 히스토리 표시
  - 로딩 상태 및 에러 처리
- `HomeView.vue`: 대시보드
  - 공고 통계 시각화
  - 전체/진행중/접수중 공고 수 표시
- `ListView.vue`: 공고 리스트 조회
  - 공고 목록 필터링 및 검색
  - 공고 상세 정보 조회

**공통 컴포넌트**:
- 채팅 메시지 컴포넌트
- 공고 카드 컴포넌트
- 필터 컴포넌트

#### 2.1.3. API 통신
- **HTTP 클라이언트**: Fetch API 또는 Axios
- **엔드포인트**: `http://localhost:8000/api/v1`
- **인증**: 세션 기반 (user_id)

---

### 2.2. Backend Layer

#### 2.2.1. 기술 스택
- **프레임워크**: FastAPI
- **언어**: Python 3.12
- **비동기 처리**: asyncio, asyncpg
- **서버**: uvicorn (ASGI)

#### 2.2.2. 주요 모듈 구조

```
back-end/zip_fit/
├── main.py              # FastAPI 앱 진입점 및 생명주기 관리
├── router.py            # API 라우터 및 세션 관리
├── chatting.py          # RAG 챗봇 서비스 로직
├── llm_handler.py       # LLM 처리 (질문 재구성, 답변 생성)
├── gongo.py            # 벡터 검색 및 DB 연동
├── config.py           # 설정 파일
├── dependencies.py     # 의존성 주입 (모델 로딩)
├── models.py          # Pydantic 모델 정의
└── info.py            # 통계 정보 제공
```

#### 2.2.3. API 엔드포인트

| 메서드 | 엔드포인트 | 기능 | 요청 형식 | 응답 형식 |
|--------|-----------|------|----------|----------|
| POST | `/api/v1/chat` | RAG 챗봇 메인 엔드포인트 | `ChatRequest` (user_id, query) | `ChatResponse` (query, answer, sources, metadata) |
| POST | `/api/v1/session/reset` | 세션 초기화 | `ResetRequest` (user_id) | 상태 메시지 |
| GET | `/api/v1/stats` | 대시보드 통계 조회 | - | 공고 통계 정보 |
| GET | `/` | 헬스 체크 | - | 서비스 상태 및 설정 정보 |

#### 2.2.4. 세션 관리

- **구현 위치**: `router.py`
- **저장 방식**: 인메모리 딕셔너리 (`user_sessions`)
- **세션 구조**: `{user_id: [대화_기록_리스트]}`
- **대화 기록 형식**: `{query, answer, sources}`

---

### 2.3. Database Layer

#### 2.3.1. 데이터베이스 구조

**PostgreSQL + pgvector 하이브리드 구조**:
- **RDB 기능**: 공고 메타데이터, 파일 정보, 관계형 데이터 관리
- **VectorDB 기능**: 문서 청크 임베딩 벡터 저장 및 유사도 검색

#### 2.3.2. 테이블 스키마

**announcements 테이블**:
- **목적**: 공고 메타데이터 저장
- **주요 컬럼**: `id`, `notice_type`, `category`, `title`, `region`, `posted_date`, `deadline_date`, `status`, `url`, `is_vectorized`
- **인덱스**: `id` (Primary Key), `region`, `category`, `notice_type`

**announcement_files 테이블**:
- **목적**: PDF 파일 정보 저장
- **주요 컬럼**: `id`, `announcement_id` (FK), `file_name`, `file_path`, `is_vectorized`
- **관계**: `announcements` 테이블과 1:N 관계

**document_chunks 테이블**:
- **목적**: 문서 청크 및 임베딩 벡터 저장 (RDB + VectorDB)
- **주요 컬럼**: `id`, `announcement_id` (FK), `file_id` (FK), `chunk_text`, `chunk_index`, `embedding` (vector(1024)), `metadata` (JSONB)
- **인덱스**: 
  - 벡터 인덱스: `embedding` 컬럼에 HNSW 인덱스 (pgvector)
  - 관계형 인덱스: `announcement_id`, `file_id`

#### 2.3.3. 벡터 검색 최적화

- **인덱스 타입**: HNSW (Hierarchical Navigable Small World)
- **거리 함수**: Cosine Distance (`<=>`)
- **검색 알고리즘**: Approximate Nearest Neighbor Search (ANN)

---

### 2.4. AI/ML Layer

#### 2.4.1. 임베딩 모델 (Embedding Model)

**모델**: BAAI/bge-m3
- **차원**: 1024
- **라이브러리**: sentence-transformers 3.3.1
- **용도**: 문서 청크 및 사용자 질문을 벡터로 변환
- **특징**: 한국어 최적화, 다국어 지원
- **로딩 방식**: 앱 시작 시 전역 변수로 로드 (싱글톤 패턴)

#### 2.4.2. 재순위화 모델 (Reranker Model)

**모델**: Dongjin-kr/ko-reranker
- **타입**: Cross-Encoder
- **용도**: 초기 검색 결과의 관련도를 재평가하여 순위 조정
- **활성화**: 환경 변수 `USE_RERANKER`로 제어 가능
- **로딩 방식**: 앱 시작 시 전역 변수로 로드 (싱글톤 패턴)

#### 2.4.3. LLM (Large Language Model)

**모델**: GPT-4o-mini (OpenAI)
- **용도**: 
  - 질문 재구성 및 분석
  - 멀티쿼리 생성
  - 맥락 분석
  - 최종 답변 생성
- **API**: OpenAI Python SDK 1.57.2
- **설정**: 
  - Temperature: 0 (질문 분석), 0.1 (답변 생성)
  - Max Tokens: 2000

---

## 3. RAG 파이프라인 상세

### 3.1. 전체 파이프라인 흐름

```
사용자 질문 입력
    ↓
[1] 질문 재구성 (Query Rewriting)
    ↓
[2] 멀티쿼리 생성 (Multi-Query Generation)
    ↓
[3] 하이브리드 검색 (Hybrid Search)
    ├─ 벡터 검색 (Vector Search)
    └─ 키워드 검색 (Keyword Search)
    ↓
[4] 검색 결과 병합 및 중복 제거
    ↓
[5] 재순위화 (Reranking)
    ↓
[6] 청크 병합 (Chunk Merging)
    ↓
[7] 컨텍스트 구성 (Context Building)
    ↓
[8] 답변 생성 (Answer Generation)
    ↓
사용자에게 답변 반환
```

### 3.2. 단계별 상세 설명

#### 3.2.1. 질문 재구성 (Query Rewriting)

**구현 위치**: `llm_handler.py` - `rewrite_query()`

**목적**: 사용자의 모호하거나 맥락에 의존적인 질문을 검색에 적합한 명확한 형태로 변환

**처리 과정**:
1. GPT-4o-mini에 사용자 질문과 대화 히스토리 전달
2. 질문에서 다음 정보 추출:
   - 지역 (region): 예) "서울", "경기"
   - 공고 유형 (notice_type): 예) "행복주택", "국민임대"
   - 카테고리 (category): "lease" 또는 "sale"
   - 재구성된 질문 (rewritten_question)
   - 검색 키워드 (search_keywords)

**출력 형식**: JSON
```json
{
  "region": "서울",
  "notice_type": "행복주택",
  "category": "lease",
  "rewritten_question": "서울 지역 행복주택 신청 자격 요건",
  "search_keywords": ["서울", "행복주택", "신청", "자격"]
}
```

#### 3.2.2. 멀티쿼리 생성 (Multi-Query Generation)

**구현 위치**: `llm_handler.py` - `generate_multi_queries()`

**목적**: 원본 질문을 다양한 표현으로 변환하여 검색 범위 확대 및 검색 정확도 향상

**처리 과정**:
1. 재구성된 질문을 기반으로 GPT-4o-mini가 다양한 관점의 쿼리 생성
2. 기본적으로 2개의 추가 쿼리 생성 (총 3개)
3. 각 쿼리는 동일한 의미를 다른 표현으로 변환

**예시**:
- 원본: "서울 행복주택 신청할 수 있어?"
- 생성 쿼리 1: "서울 지역 행복주택 모집 공고"
- 생성 쿼리 2: "서울 행복주택 입주 신청 조건"

#### 3.2.3. 하이브리드 검색 (Hybrid Search)

**구현 위치**: `gongo.py` - `multi_query_hybrid_search()`

**목적**: 벡터 검색과 키워드 검색을 결합하여 의미적 유사성과 정확한 단어 매칭을 동시에 활용

**벡터 검색 (Vector Search)**:
- **함수**: `vector_search()`
- **방법**: 
  1. 각 멀티쿼리를 BAAI/bge-m3로 임베딩 벡터 변환
  2. pgvector의 cosine distance 연산자 (`<=>`) 사용
  3. 유사도 점수 계산: `similarity = 1 - (embedding <=> query_embedding)`
  4. 상위 K개 결과 반환 (기본 K=15)
- **필터링**: 지역, 유형, 카테고리별 WHERE 절 필터링
- **SQL 예시**:
  ```sql
  SELECT ..., (1 - (dc.embedding <=> $1::vector)) as similarity
  FROM document_chunks dc
  JOIN announcements a ON dc.announcement_id = a.id
  WHERE a.region LIKE '%서울%' AND a.category = 'lease'
  ORDER BY dc.embedding <=> $1::vector
  LIMIT 15
  ```

**키워드 검색 (Keyword Search)**:
- **함수**: `keyword_search()`
- **방법**: 
  1. 재구성된 질문에서 추출한 키워드 사용
  2. PostgreSQL의 LIKE 연산자로 정확한 단어 매칭
  3. 여러 키워드에 대해 OR 조건으로 검색
- **SQL 예시**:
  ```sql
  SELECT DISTINCT ON (dc.id) ...
  FROM document_chunks dc
  JOIN announcements a ON dc.announcement_id = a.id
  WHERE (dc.chunk_text LIKE '%서울%' OR dc.chunk_text LIKE '%행복주택%')
  LIMIT 10
  ```

**결과 병합**:
- 벡터 검색 결과와 키워드 검색 결과를 병합
- 중복 제거: 동일한 청크 ID는 하나만 유지
- 점수 정규화: 벡터 유사도 점수와 키워드 매칭 점수를 가중 평균

#### 3.2.4. 재순위화 (Reranking)

**구현 위치**: `gongo.py` - `rerank_results()`

**목적**: 초기 검색 결과를 질문과의 관련도에 따라 더 정교하게 재정렬

**처리 과정**:
1. Cross-Encoder 기반 Reranker 모델 사용 (Dongjin-kr/ko-reranker)
2. 각 검색 결과에 대해 (질문, 청크 텍스트) 쌍을 모델에 입력
3. 관련도 점수 계산 (0~1 사이)
4. 점수 기준으로 내림차순 정렬
5. 상위 K개 선택 (기본 K=8)

**활성화 조건**: 환경 변수 `USE_RERANKER=true` (기본값)

**장점**:
- Bi-Encoder보다 정확한 관련도 평가
- 질문과 문서의 상호작용을 직접 모델링
- 검색 정확도 향상

#### 3.2.5. 청크 병합 (Chunk Merging)

**구현 위치**: `gongo.py` - `merge_chunks()`

**목적**: 동일 공고의 여러 청크를 하나로 병합하여 문맥 보존 및 중복 제거

**처리 과정**:
1. 공고 ID(`announcement_id`) 기준으로 그룹화
2. 각 공고 내에서 청크 인덱스(`chunk_index`) 순서로 정렬
3. 청크 텍스트를 순서대로 연결
4. 메타데이터 통합 (최고 관련도 점수, 청크 개수 등)

**결과 구조**:
```python
{
  "announcement_id": "LH_lease_1",
  "title": "서울시 강남구 행복주택 모집공고",
  "merged_text": "청크1\n\n청크2\n\n청크3",
  "rerank_score": 0.95,
  "num_chunks": 3,
  ...
}
```

#### 3.2.6. 컨텍스트 구성 (Context Building)

**구현 위치**: `gongo.py` - `build_context()`

**목적**: 검색된 공고 정보를 LLM이 이해하기 쉬운 구조화된 형식으로 구성

**구성 형식**:
```
[공고 1]
제목: 서울시 강남구 행복주택 모집공고
지역: 서울
유형: 행복주택
카테고리: 임대
관련도: 0.95

내용:
[병합된 청크 텍스트]

---

[공고 2]
...
```

**포함 정보**:
- 공고 메타데이터 (제목, 지역, 유형, 카테고리)
- 관련도 점수 (rerank_score)
- 병합된 문서 내용

#### 3.2.7. 답변 생성 (Answer Generation)

**구현 위치**: `llm_handler.py` - `generate_answer()`

**목적**: 제공된 컨텍스트를 바탕으로 사용자 질문에 대한 정확하고 친절한 답변 생성

**프롬프트 구조**:
- **시스템 프롬프트**: LH 공사 임대/분양 공고 전문 상담사 역할 정의
- **사용자 프롬프트**: 
  - 제공된 문서 컨텍스트
  - 이전 대화 히스토리 (최근 3개)
  - 사용자 질문

**답변 원칙**:
1. **정확성**: 제공된 문서만을 근거로 답변
2. **구체성**: 숫자, 날짜, 조건을 정확히 인용
3. **완전성**: 관련된 모든 중요 정보 포함
4. **명확성**: 복잡한 조건은 단계별로 설명
5. **친절함**: 전문 용어는 쉽게 풀어 설명

**출력 형식**:
- 마크다운 형식 지원 (표, 목록 등)
- 출처 명시: `[공고 1, 2 참조]`

---

## 4. 맥락 인식 대화 (Context-Aware Chat)

### 4.1. 맥락 분석

**구현 위치**: `llm_handler.py` - `analyze_context()`

**목적**: 현재 질문이 이전 대화와 이어지는지 판단

**분석 결과**:
- `is_context_question`: 맥락 질문 여부 (Boolean)
- `context_type`: 맥락 유형
  - `new_question`: 새로운 질문
  - `follow_up`: 이전 질문의 후속 질문
  - `meta_conversation`: 대화 자체에 대한 질문 (예: "이전에 뭐 물어봤지?")
- `referenced_announcement_indices`: 참조된 공고 인덱스 리스트

### 4.2. 처리 전략

**새로운 질문**:
- 전체 데이터베이스에서 검색
- 표준 RAG 파이프라인 실행

**후속 질문**:
- 이전 대화에서 언급된 공고 ID 범위 내에서 우선 검색
- 필터링: `filter_ids` 파라미터 사용
- 맥락 유지로 더 정확한 답변 생성

**대화 메타 질문**:
- 검색 없이 이전 대화 히스토리만으로 답변 생성
- 예: "이전에 뭐 물어봤지?", "그 공고 신청 기간 언제야?"

---

## 5. 데이터 흐름 (Data Flow)

### 5.1. 질의-응답 흐름

### 5.2. 데이터 수집 및 전처리 흐름

<img width="929" alt="SKN_19_08_LLM_img_zipfit-architecture-diagrams" src="https://github.com/user-attachments/assets/55f02eca-29c1-44fc-8225-19e7c7ad436f" />

---

## 6. 성능 최적화 전략

### 6.1. 비동기 처리

- **Backend**: FastAPI의 비동기 기능 활용
- **Database**: asyncpg를 통한 비동기 PostgreSQL 연결
- **LLM API**: AsyncOpenAI를 통한 비동기 API 호출
- **효과**: 동시 요청 처리 능력 향상, 응답 시간 단축

### 6.2. 모델 캐싱

- **임베딩 모델**: 앱 시작 시 한 번만 로드, 전역 변수로 관리
- **Reranker 모델**: 앱 시작 시 한 번만 로드, 전역 변수로 관리
- **효과**: 요청마다 모델 로딩 시간 제거, 메모리 효율성 향상

### 6.3. 벡터 검색 최적화

- **인덱스**: pgvector의 HNSW 인덱스 활용
- **필터링**: WHERE 절에서 필터링하여 검색 범위 축소
- **효과**: 대규모 데이터셋에서도 빠른 검색 속도 유지

### 6.4. 세션 관리 최적화

- **저장 방식**: 인메모리 딕셔너리 (빠른 접근)
- **히스토리 제한**: 최근 대화만 유지 (메모리 절약)
- **효과**: 낮은 지연 시간, 확장 가능한 구조

---

## 7. 보안 및 확장성

### 7.1. 보안 고려사항

- **CORS 설정**: 특정 도메인만 허용
- **입력 검증**: Pydantic 모델을 통한 요청 데이터 검증
- **에러 처리**: 민감한 정보 노출 방지
- **API 키 관리**: 환경 변수를 통한 안전한 키 관리

### 7.2. 확장성 고려사항

- **수평 확장**: Stateless API 설계로 여러 인스턴스 실행 가능
- **세션 관리**: 향후 Redis 등 외부 저장소로 확장 가능
- **데이터베이스**: 읽기 전용 복제본 추가 가능
- **모델 서빙**: 별도 모델 서버로 분리 가능

---

## 8. 모니터링 및 로깅

### 8.1. 로깅 전략

- **요청 로깅**: 각 API 요청의 시작/종료 시간 기록
- **RAG 파이프라인 로깅**: 각 단계별 처리 시간 및 결과 기록
- **에러 로깅**: 예외 발생 시 상세 스택 트레이스 기록

### 8.2. 성능 메트릭

- **응답 시간**: 전체 요청 처리 시간 측정
- **검색 시간**: 벡터 검색 및 재순위화 시간 측정
- **LLM 호출 시간**: 질문 재구성 및 답변 생성 시간 측정

---

## 9. 향후 개선 방향

### 9.1. 기능 확장

- **자격 진단**: 사용자 정보 기반 자동 자격 판단
- **계약 지원**: 계약서 작성 및 검토 지원
- **대출 정보**: 주택 금융 정보 제공

### 9.2. 기술 개선

- **캐싱**: 자주 묻는 질문에 대한 답변 캐싱
- **스트리밍**: 답변 생성 시 스트리밍 응답 지원
- **멀티모달**: 이미지 및 표 인식 기능 추가

### 9.3. 데이터 확장

- **GH, SH 공고**: 경기주택도시공사, 서울주택도시공사 공고 추가
- **전국 확대**: 서울/경기 외 지역 공고 확대
- **실시간 업데이트**: 공고 변경사항 자동 반영

---

## 10. 참고 자료

- [개발된 소프트웨어 문서](./04_개발된_소프트웨어.md)
- [DB 연동 구현 코드](./05_DB_연동_구현_코드.md)
- [데이터 전처리 문서](./02_데이터_전처리_문서.md)
- [FastAPI 공식 문서](https://fastapi.tiangolo.com/)
- [pgvector 공식 문서](https://github.com/pgvector/pgvector)
- [Vue 3 공식 문서](https://vuejs.org/)



